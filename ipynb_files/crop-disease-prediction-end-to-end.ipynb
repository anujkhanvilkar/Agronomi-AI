{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4ab3c9",
   "metadata": {
    "papermill": {
     "duration": 0.007328,
     "end_time": "2023-03-31T09:19:47.292207",
     "exception": false,
     "start_time": "2023-03-31T09:19:47.284879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e558f4e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:19:47.307403Z",
     "iopub.status.busy": "2023-03-31T09:19:47.306508Z",
     "iopub.status.idle": "2023-03-31T09:19:57.567344Z",
     "shell.execute_reply": "2023-03-31T09:19:57.565844Z"
    },
    "papermill": {
     "duration": 10.272013,
     "end_time": "2023-03-31T09:19:57.570480",
     "exception": false,
     "start_time": "2023-03-31T09:19:47.298467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf8ff9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:19:57.585451Z",
     "iopub.status.busy": "2023-03-31T09:19:57.584612Z",
     "iopub.status.idle": "2023-03-31T09:19:57.593596Z",
     "shell.execute_reply": "2023-03-31T09:19:57.592044Z"
    },
    "papermill": {
     "duration": 0.019659,
     "end_time": "2023-03-31T09:19:57.596452",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.576793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "target_size = (image_size, image_size)\n",
    "input_shape = (image_size, image_size, 3)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100d1c8",
   "metadata": {
    "papermill": {
     "duration": 0.006887,
     "end_time": "2023-03-31T09:19:57.609535",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.602648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get data\n",
    "\n",
    "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better.\n",
    "\n",
    "In TensorFlow this can be done via the `tf.keras.preprocessing.image.ImageDataGenerator` class. This class allows you to:\n",
    "\n",
    "- configure random transformations and normalization operations to be done on your image data during training\n",
    "- instantiate generators of augmented image batches (and their labels) via `.flow(data, labels)` or `.flow_from_directory(directory)`. These generators can then be used with the `tf.keras` model methods that accept data generators as inputs, `fit`, `evaluate` and `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483df90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:19:57.624376Z",
     "iopub.status.busy": "2023-03-31T09:19:57.623932Z",
     "iopub.status.idle": "2023-03-31T09:19:57.630107Z",
     "shell.execute_reply": "2023-03-31T09:19:57.628774Z"
    },
    "papermill": {
     "duration": 0.016345,
     "end_time": "2023-03-31T09:19:57.632514",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.616169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = os.path.join(base_dir,\"train\")\n",
    "test_dir = os.path.join(base_dir,\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29290f",
   "metadata": {
    "papermill": {
     "duration": 0.005911,
     "end_time": "2023-03-31T09:19:57.644683",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.638772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Identify Plant Diseases\n",
    "\n",
    "We use the PlantVillage dataset [1] by Hughes et al. consists of about 87,000 healthy and unhealthy leaf images divided into 38 categories by species and disease. Here we provide a subset of our experiments on working with this data. We also end up transfer learning from MobileNet and use the weights from pre-training on ImageNet.\n",
    "\n",
    "* ![PlantVillage Dataset Samples](https://i.imgur.com/Zcxdrlc.png)\n",
    "Figure 1. PlantVillage Dataset Samples\n",
    "\n",
    "## Classes\n",
    "\n",
    "The following 38 classes are availaible in the dataset\n",
    "\n",
    "- `Apple___Apple_scab` \n",
    "- `Apple___Black_rot` \n",
    "- `Apple___Cedar_apple_rust` \n",
    "- `Apple___healthy` \n",
    "- `Blueberry___healthy` \n",
    "- `Cherry_(including_sour)___Powdery_mildew` \n",
    "- `Cherry_(including_sour)___healthy` \n",
    "- `Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot` \n",
    "- `Corn_(maize)___Common_rust_` \n",
    "- `Corn_(maize)___Northern_Leaf_Blight` \n",
    "- `Corn_(maize)___healthy', 'Grape___Black_rot` \n",
    "- `Grape___Leaf_blight_(Isariopsis_Leaf_Spot)` \n",
    "- `Grape___healthy` \n",
    "- `Orange___Haunglongbing_(Citrus_greening)` \n",
    "- `Peach___Bacterial_spot` \n",
    "- `Peach___healthy` \n",
    "- `Pepper,_bell___Bacterial_spot` \n",
    "- `Pepper,_bell___healthy` \n",
    "- `Potato___Early_blight` \n",
    "- `Potato___Late_blight` \n",
    "- `Potato___healthy` \n",
    "- `Raspberry___healthy` \n",
    "- `Soybean___healthy` \n",
    "- `Squash___Powdery_mildew` \n",
    "- `Strawberry___Leaf_scorch` \n",
    "- `Strawberry___healthy` \n",
    "- `Tomato___Bacterial_spot` \n",
    "- `Tomato___Late_blight` \n",
    "- `Tomato___Leaf_Mold` \n",
    "- `Tomato___Septoria_leaf_spot` \n",
    "- `Tomato___Spider_mites Two-spotted_spider_mite` \n",
    "- `Tomato___Target_Spot` \n",
    "- `Tomato___Tomato_Yellow_Leaf_Curl_Virus` \n",
    "- `Tomato___Tomato_mosaic_virus` \n",
    "- `Tomato___healthy`\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Hughes, David P., and Marcel Salathe. “An Open Access Repository of Images on Plant Health to Enable the Development of Mobile Disease Diagnostics.” ArXiv:1511.08060 [Cs], Apr. 2016. arXiv.org, http://arxiv.org/abs/1511.08060.\n",
    "\n",
    "[2] Howard, Andrew G., et al. “MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications.” ArXiv:1704.04861 [Cs], Apr. 2017. arXiv.org, http://arxiv.org/abs/1704.04861.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a24b10",
   "metadata": {
    "papermill": {
     "duration": 0.005865,
     "end_time": "2023-03-31T09:19:57.656686",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.650821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We make the following augmentations to the images:\n",
    "\n",
    "- `width_shift` and `height_shift` are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally\n",
    "- `rescale` is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n",
    "- `shear_range` is for randomly applying shearing transformations\n",
    "- `zoom_range` is for randomly zooming inside pictures\n",
    "- `fill_mode` is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a278ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:19:57.671099Z",
     "iopub.status.busy": "2023-03-31T09:19:57.670624Z",
     "iopub.status.idle": "2023-03-31T09:19:57.677676Z",
     "shell.execute_reply": "2023-03-31T09:19:57.676504Z"
    },
    "papermill": {
     "duration": 0.017046,
     "end_time": "2023-03-31T09:19:57.680102",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.663056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0,\n",
    "                                                             shear_range = 0.2,\n",
    "                                                             zoom_range = 0.2,\n",
    "                                                             width_shift_range = 0.2,\n",
    "                                                             height_shift_range = 0.2,\n",
    "                                                             fill_mode=\"nearest\")\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ce2e3",
   "metadata": {
    "papermill": {
     "duration": 0.005746,
     "end_time": "2023-03-31T09:19:57.692107",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.686361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's prepare our data. We will use `.flow_from_directory()` to generate batches of image data (and their labels) directly from our images in their respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40656d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:19:57.706710Z",
     "iopub.status.busy": "2023-03-31T09:19:57.705843Z",
     "iopub.status.idle": "2023-03-31T09:20:50.946617Z",
     "shell.execute_reply": "2023-03-31T09:20:50.945278Z"
    },
    "papermill": {
     "duration": 53.251586,
     "end_time": "2023-03-31T09:20:50.949652",
     "exception": false,
     "start_time": "2023-03-31T09:19:57.698066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39932\\2459731960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_data = train_datagen.flow_from_directory(train_dir,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                class_mode = \"categorical\")\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                 \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m         \"\"\"\n\u001b[1;32m-> 1648\u001b[1;33m         return DirectoryIterator(\n\u001b[0m\u001b[0;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\\\\train'"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size = (image_size, image_size),\n",
    "                                               batch_size = batch_size,\n",
    "                                               class_mode = \"categorical\")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size = (image_size, image_size),\n",
    "                                             batch_size = batch_size,\n",
    "                                             class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b1fca",
   "metadata": {
    "papermill": {
     "duration": 0.005983,
     "end_time": "2023-03-31T09:20:50.962355",
     "exception": false,
     "start_time": "2023-03-31T09:20:50.956372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a classes index file\n",
    "\n",
    "We also want to know which class corresponds to which species and disease so we also create a `json` file which shows corresponding labels and class indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b3766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:20:50.977238Z",
     "iopub.status.busy": "2023-03-31T09:20:50.976472Z",
     "iopub.status.idle": "2023-03-31T09:20:50.982689Z",
     "shell.execute_reply": "2023-03-31T09:20:50.981176Z"
    },
    "papermill": {
     "duration": 0.016832,
     "end_time": "2023-03-31T09:20:50.985339",
     "exception": false,
     "start_time": "2023-03-31T09:20:50.968507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = list(train_data.class_indices.keys())\n",
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e056be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:20:51.000364Z",
     "iopub.status.busy": "2023-03-31T09:20:50.999544Z",
     "iopub.status.idle": "2023-03-31T09:20:51.008611Z",
     "shell.execute_reply": "2023-03-31T09:20:51.007388Z"
    },
    "papermill": {
     "duration": 0.019436,
     "end_time": "2023-03-31T09:20:51.011179",
     "exception": false,
     "start_time": "2023-03-31T09:20:50.991743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('class_indices.json','w') as f:\n",
    "  json.dump(train_data.class_indices, f)\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'class_indices.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9333466",
   "metadata": {
    "papermill": {
     "duration": 0.006992,
     "end_time": "2023-03-31T09:20:51.024741",
     "exception": false,
     "start_time": "2023-03-31T09:20:51.017749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "We first get the base MobileNet model without including the top layers since we want to use it for 38 classes and us the pre-trained weights for ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915e531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:20:51.039778Z",
     "iopub.status.busy": "2023-03-31T09:20:51.038949Z",
     "iopub.status.idle": "2023-03-31T09:20:52.496137Z",
     "shell.execute_reply": "2023-03-31T09:20:52.494742Z"
    },
    "papermill": {
     "duration": 1.468248,
     "end_time": "2023-03-31T09:20:52.499338",
     "exception": false,
     "start_time": "2023-03-31T09:20:51.031090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNet(weights = \"imagenet\",\n",
    "                                             include_top = False,\n",
    "                                             input_shape = input_shape)\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f30bac",
   "metadata": {
    "papermill": {
     "duration": 0.006822,
     "end_time": "2023-03-31T09:20:52.513188",
     "exception": false,
     "start_time": "2023-03-31T09:20:52.506366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now create a small upstream model on top of the MobileNet using the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433319b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:20:52.530773Z",
     "iopub.status.busy": "2023-03-31T09:20:52.530319Z",
     "iopub.status.idle": "2023-03-31T09:20:52.835303Z",
     "shell.execute_reply": "2023-03-31T09:20:52.833810Z"
    },
    "papermill": {
     "duration": 0.317515,
     "end_time": "2023-03-31T09:20:52.838267",
     "exception": false,
     "start_time": "2023-03-31T09:20:52.520752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = input_shape)\n",
    "\n",
    "x = base_model(inputs, training = False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(len(categories), \n",
    "                          activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs, \n",
    "                    outputs = x, \n",
    "                    name=\"LeafDisease_MobileNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d6e1c",
   "metadata": {
    "papermill": {
     "duration": 0.006617,
     "end_time": "2023-03-31T09:20:52.851822",
     "exception": false,
     "start_time": "2023-03-31T09:20:52.845205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In our multiple experiments we found out Adam optimizer to work really well with it's default learning rate, $\\beta_1$, $\\beta_2$ and $\\epsilon$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb41ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:20:52.867849Z",
     "iopub.status.busy": "2023-03-31T09:20:52.867408Z",
     "iopub.status.idle": "2023-03-31T09:20:52.895517Z",
     "shell.execute_reply": "2023-03-31T09:20:52.894120Z"
    },
    "papermill": {
     "duration": 0.039791,
     "end_time": "2023-03-31T09:20:52.898501",
     "exception": false,
     "start_time": "2023-03-31T09:20:52.858710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
    "                       'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2dd8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T09:20:52.914752Z",
     "iopub.status.busy": "2023-03-31T09:20:52.914340Z",
     "iopub.status.idle": "2023-03-31T11:15:20.048243Z",
     "shell.execute_reply": "2023-03-31T11:15:20.046592Z"
    },
    "papermill": {
     "duration": 6867.41145,
     "end_time": "2023-03-31T11:15:20.316942",
     "exception": false,
     "start_time": "2023-03-31T09:20:52.905492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_data,\n",
    "                    validation_data=test_data,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=150,\n",
    "                    validation_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646b462",
   "metadata": {
    "papermill": {
     "duration": 0.253382,
     "end_time": "2023-03-31T11:15:20.827310",
     "exception": false,
     "start_time": "2023-03-31T11:15:20.573928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Review the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc309ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T11:15:21.337791Z",
     "iopub.status.busy": "2023-03-31T11:15:21.335932Z",
     "iopub.status.idle": "2023-03-31T11:15:21.641069Z",
     "shell.execute_reply": "2023-03-31T11:15:21.639661Z"
    },
    "papermill": {
     "duration": 0.564475,
     "end_time": "2023-03-31T11:15:21.643968",
     "exception": false,
     "start_time": "2023-03-31T11:15:21.079493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs,loss,c=\"red\",label=\"Training\")\n",
    "plt.plot(epochs,val_loss,c=\"blue\",label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706088f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T11:15:22.155578Z",
     "iopub.status.busy": "2023-03-31T11:15:22.155146Z",
     "iopub.status.idle": "2023-03-31T11:15:22.439211Z",
     "shell.execute_reply": "2023-03-31T11:15:22.437716Z"
    },
    "papermill": {
     "duration": 0.54465,
     "end_time": "2023-03-31T11:15:22.442117",
     "exception": false,
     "start_time": "2023-03-31T11:15:21.897467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs,acc,c=\"red\",label=\"Training\")\n",
    "plt.plot(epochs,val_acc,c=\"blue\",label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463cda02",
   "metadata": {
    "papermill": {
     "duration": 0.255082,
     "end_time": "2023-03-31T11:15:22.959380",
     "exception": false,
     "start_time": "2023-03-31T11:15:22.704298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save the model\n",
    "We finally save the model in the standard TensorFlow 2 SavedModel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067dc1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T11:15:23.566227Z",
     "iopub.status.busy": "2023-03-31T11:15:23.565314Z",
     "iopub.status.idle": "2023-03-31T11:15:37.341767Z",
     "shell.execute_reply": "2023-03-31T11:15:37.340126Z"
    },
    "papermill": {
     "duration": 14.11882,
     "end_time": "2023-03-31T11:15:37.345403",
     "exception": false,
     "start_time": "2023-03-31T11:15:23.226583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('plant_disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e55c7",
   "metadata": {
    "papermill": {
     "duration": 0.259573,
     "end_time": "2023-03-31T11:15:37.876132",
     "exception": false,
     "start_time": "2023-03-31T11:15:37.616559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Converting to tflite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d4b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T11:15:38.408345Z",
     "iopub.status.busy": "2023-03-31T11:15:38.407891Z",
     "iopub.status.idle": "2023-03-31T11:16:01.705478Z",
     "shell.execute_reply": "2023-03-31T11:16:01.703962Z"
    },
    "papermill": {
     "duration": 23.568069,
     "end_time": "2023-03-31T11:16:01.708527",
     "exception": false,
     "start_time": "2023-03-31T11:15:38.140458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6989.456024,
   "end_time": "2023-03-31T11:16:05.516788",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-31T09:19:36.060764",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
